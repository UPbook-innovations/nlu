{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "document_normalizer_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXIWSN300w5v"
      },
      "source": [
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/text_pre_processing_and_cleaning/document_normalizer_demo.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "The DocumentNormalizer extracts content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abuB9K1_QVuL"
      },
      "source": [
        "import os\n",
        "! apt-get update -qq > /dev/null   \n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! pip install nlu  pyspark==2.4.7\n",
        "import nlu\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SQzdgwyQ65Q",
        "outputId": "f689174a-8b8f-41b8-9ca4-dd903489657f"
      },
      "source": [
        "pipe = nlu.load('norm_document')\n",
        "data = '<!DOCTYPE html> <html> <head> <title>Example</title> </head> <body> <p>This is an example of a simple HTML page with one paragraph.</p> </body> </html>'\n",
        "df = pipe.predict(data,output_level='document')\n",
        "print(df['normalized_document'])\n",
        "print(df.iloc[0]['normalized_document'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "origin_index\n",
            "0    [ Example This is an example of a simple HTML ...\n",
            "Name: normalized_document, dtype: object\n",
            "[' Example This is an example of a simple HTML page with one paragraph.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o73dDzocR7L_",
        "outputId": "732fe2eb-c51e-4108-b5eb-aac6a88873ba"
      },
      "source": [
        "pipe.print_info()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following parameters are configurable for this NLU pipeline (You can copy paste the examples) :\n",
            ">>> pipe['document_normalizer'] has settable params:\n",
            "pipe['document_normalizer'].setAction('clean')           | Info: action to perform applying regex patterns on text | Currently set to : clean\n",
            "pipe['document_normalizer'].setPatterns(['<[^>]*>'])     | Info: normalization regex patterns which match will be removed from document. Defaults is <[^>]*> | Currently set to : ['<[^>]*>']\n",
            "pipe['document_normalizer'].setReplacement(' ')          | Info: replacement string to apply when regexes match | Currently set to :  \n",
            "pipe['document_normalizer'].setLowercase(False)          | Info: whether to convert strings to lowercase | Currently set to : False\n",
            "pipe['document_normalizer'].setPolicy('pretty_all')      | Info: policy to remove pattern from text | Currently set to : pretty_all\n",
            "pipe['document_normalizer'].setEncoding('UTF-8')         | Info: file encoding to apply on normalized documents | Currently set to : UTF-8\n",
            ">>> pipe['default_tokenizer'] has settable params:\n",
            "pipe['default_tokenizer'].setTargetPattern('\\S+')        | Info: pattern to grab from text as token candidates. Defaults \\S+ | Currently set to : \\S+\n",
            "pipe['default_tokenizer'].setContextChars(['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"])  | Info: character list used to separate from token boundaries | Currently set to : ['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"]\n",
            "pipe['default_tokenizer'].setCaseSensitiveExceptions(True)  | Info: Whether to care for case sensitiveness in exceptions | Currently set to : True\n",
            "pipe['default_tokenizer'].setMinLength(0)                | Info: Set the minimum allowed legth for each token | Currently set to : 0\n",
            "pipe['default_tokenizer'].setMaxLength(99999)            | Info: Set the maximum allowed legth for each token | Currently set to : 99999\n",
            ">>> pipe['document_assembler'] has settable params:\n",
            "pipe['document_assembler'].setCleanupMode('shrink')      | Info: possible values: disabled, inplace, inplace_full, shrink, shrink_full, each, each_full, delete_full | Currently set to : shrink\n",
            ">>> pipe['sentence_detector'] has settable params:\n",
            "pipe['sentence_detector'].setUseAbbreviations(True)      | Info: whether to apply abbreviations at sentence detection | Currently set to : True\n",
            "pipe['sentence_detector'].setDetectLists(True)           | Info: whether detect lists during sentence detection | Currently set to : True\n",
            "pipe['sentence_detector'].setUseCustomBoundsOnly(False)  | Info: Only utilize custom bounds in sentence detection | Currently set to : False\n",
            "pipe['sentence_detector'].setCustomBounds([])            | Info: characters used to explicitly mark sentence bounds | Currently set to : []\n",
            "pipe['sentence_detector'].setExplodeSentences(False)     | Info: whether to explode each sentence into a different row, for better parallelization. Defaults to false. | Currently set to : False\n",
            "pipe['sentence_detector'].setMinLength(0)                | Info: Set the minimum allowed length for each sentence. | Currently set to : 0\n",
            "pipe['sentence_detector'].setMaxLength(99999)            | Info: Set the maximum allowed length for each sentence | Currently set to : 99999\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}